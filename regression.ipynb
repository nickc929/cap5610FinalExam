{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "Nicholas Cunningham  \n",
    "CAP 5610, Final Exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "df = pd.read_csv('Exam Datasets\\\\regression_data.csv', header = 0)\n",
    "\n",
    "X = df.iloc[:, 3:20].values\n",
    "y = df.iloc[:, 2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Analysis\n",
    "\n",
    "df.corr() and df.describe() were used to determine the correlation between each attribute in the dataset and general statistics about each attribute. The information was used to select which attributes to keep and which to discard. The data was processed without normalization to determine the performance on the raw attributes. A further analysis could determine whether normalization would improve the performance and by how much.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016762</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.005160</td>\n",
       "      <td>-0.012258</td>\n",
       "      <td>-0.132109</td>\n",
       "      <td>0.018525</td>\n",
       "      <td>-0.002721</td>\n",
       "      <td>0.011592</td>\n",
       "      <td>-0.023783</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>-0.010842</td>\n",
       "      <td>-0.005151</td>\n",
       "      <td>0.021380</td>\n",
       "      <td>-0.016907</td>\n",
       "      <td>-0.008224</td>\n",
       "      <td>-0.001891</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>-0.002901</td>\n",
       "      <td>-0.138798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>-0.016762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.308350</td>\n",
       "      <td>0.525138</td>\n",
       "      <td>0.702035</td>\n",
       "      <td>0.089661</td>\n",
       "      <td>0.256794</td>\n",
       "      <td>0.266369</td>\n",
       "      <td>0.397293</td>\n",
       "      <td>0.036362</td>\n",
       "      <td>0.667434</td>\n",
       "      <td>0.605567</td>\n",
       "      <td>0.323816</td>\n",
       "      <td>0.054012</td>\n",
       "      <td>0.126434</td>\n",
       "      <td>-0.053203</td>\n",
       "      <td>0.307003</td>\n",
       "      <td>0.021626</td>\n",
       "      <td>0.585379</td>\n",
       "      <td>0.082447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.308350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.515884</td>\n",
       "      <td>0.576671</td>\n",
       "      <td>0.031703</td>\n",
       "      <td>0.175429</td>\n",
       "      <td>-0.006582</td>\n",
       "      <td>0.079532</td>\n",
       "      <td>0.028472</td>\n",
       "      <td>0.356967</td>\n",
       "      <td>0.477600</td>\n",
       "      <td>0.303093</td>\n",
       "      <td>0.154178</td>\n",
       "      <td>0.018841</td>\n",
       "      <td>-0.152668</td>\n",
       "      <td>-0.008931</td>\n",
       "      <td>0.129473</td>\n",
       "      <td>0.391638</td>\n",
       "      <td>0.029244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>0.005160</td>\n",
       "      <td>0.525138</td>\n",
       "      <td>0.515884</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.754665</td>\n",
       "      <td>0.087740</td>\n",
       "      <td>0.500653</td>\n",
       "      <td>0.063744</td>\n",
       "      <td>0.187737</td>\n",
       "      <td>-0.124982</td>\n",
       "      <td>0.664983</td>\n",
       "      <td>0.685342</td>\n",
       "      <td>0.283770</td>\n",
       "      <td>0.506019</td>\n",
       "      <td>0.050739</td>\n",
       "      <td>-0.203866</td>\n",
       "      <td>0.024573</td>\n",
       "      <td>0.223042</td>\n",
       "      <td>0.568634</td>\n",
       "      <td>0.087175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_living</th>\n",
       "      <td>-0.012258</td>\n",
       "      <td>0.702035</td>\n",
       "      <td>0.576671</td>\n",
       "      <td>0.754665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.172826</td>\n",
       "      <td>0.353949</td>\n",
       "      <td>0.103818</td>\n",
       "      <td>0.284611</td>\n",
       "      <td>-0.058753</td>\n",
       "      <td>0.762704</td>\n",
       "      <td>0.876597</td>\n",
       "      <td>0.435043</td>\n",
       "      <td>0.318049</td>\n",
       "      <td>0.055363</td>\n",
       "      <td>-0.199430</td>\n",
       "      <td>0.052529</td>\n",
       "      <td>0.240223</td>\n",
       "      <td>0.756420</td>\n",
       "      <td>0.183286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_lot</th>\n",
       "      <td>-0.132109</td>\n",
       "      <td>0.089661</td>\n",
       "      <td>0.031703</td>\n",
       "      <td>0.087740</td>\n",
       "      <td>0.172826</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005201</td>\n",
       "      <td>0.021604</td>\n",
       "      <td>0.074710</td>\n",
       "      <td>-0.008958</td>\n",
       "      <td>0.113621</td>\n",
       "      <td>0.183512</td>\n",
       "      <td>0.015286</td>\n",
       "      <td>0.053080</td>\n",
       "      <td>0.007644</td>\n",
       "      <td>-0.129574</td>\n",
       "      <td>-0.085683</td>\n",
       "      <td>0.229521</td>\n",
       "      <td>0.144608</td>\n",
       "      <td>0.718557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floors</th>\n",
       "      <td>0.018525</td>\n",
       "      <td>0.256794</td>\n",
       "      <td>0.175429</td>\n",
       "      <td>0.500653</td>\n",
       "      <td>0.353949</td>\n",
       "      <td>-0.005201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023698</td>\n",
       "      <td>0.029444</td>\n",
       "      <td>-0.263768</td>\n",
       "      <td>0.458183</td>\n",
       "      <td>0.523885</td>\n",
       "      <td>-0.245705</td>\n",
       "      <td>0.489319</td>\n",
       "      <td>0.006338</td>\n",
       "      <td>-0.059121</td>\n",
       "      <td>0.049614</td>\n",
       "      <td>0.125419</td>\n",
       "      <td>0.279885</td>\n",
       "      <td>-0.011269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterfront</th>\n",
       "      <td>-0.002721</td>\n",
       "      <td>0.266369</td>\n",
       "      <td>-0.006582</td>\n",
       "      <td>0.063744</td>\n",
       "      <td>0.103818</td>\n",
       "      <td>0.021604</td>\n",
       "      <td>0.023698</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.401857</td>\n",
       "      <td>0.016653</td>\n",
       "      <td>0.082775</td>\n",
       "      <td>0.072075</td>\n",
       "      <td>0.080588</td>\n",
       "      <td>-0.026161</td>\n",
       "      <td>0.092885</td>\n",
       "      <td>0.030285</td>\n",
       "      <td>-0.014274</td>\n",
       "      <td>-0.041910</td>\n",
       "      <td>0.086463</td>\n",
       "      <td>0.030703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>view</th>\n",
       "      <td>0.011592</td>\n",
       "      <td>0.397293</td>\n",
       "      <td>0.079532</td>\n",
       "      <td>0.187737</td>\n",
       "      <td>0.284611</td>\n",
       "      <td>0.074710</td>\n",
       "      <td>0.029444</td>\n",
       "      <td>0.401857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045990</td>\n",
       "      <td>0.251321</td>\n",
       "      <td>0.167649</td>\n",
       "      <td>0.276947</td>\n",
       "      <td>-0.053440</td>\n",
       "      <td>0.103917</td>\n",
       "      <td>0.084827</td>\n",
       "      <td>0.006157</td>\n",
       "      <td>-0.078400</td>\n",
       "      <td>0.280439</td>\n",
       "      <td>0.072575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition</th>\n",
       "      <td>-0.023783</td>\n",
       "      <td>0.036362</td>\n",
       "      <td>0.028472</td>\n",
       "      <td>-0.124982</td>\n",
       "      <td>-0.058753</td>\n",
       "      <td>-0.008958</td>\n",
       "      <td>-0.263768</td>\n",
       "      <td>0.016653</td>\n",
       "      <td>0.045990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.144674</td>\n",
       "      <td>-0.158214</td>\n",
       "      <td>0.174105</td>\n",
       "      <td>-0.361417</td>\n",
       "      <td>-0.060618</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>-0.014941</td>\n",
       "      <td>-0.106500</td>\n",
       "      <td>-0.092824</td>\n",
       "      <td>-0.003406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.667434</td>\n",
       "      <td>0.356967</td>\n",
       "      <td>0.664983</td>\n",
       "      <td>0.762704</td>\n",
       "      <td>0.113621</td>\n",
       "      <td>0.458183</td>\n",
       "      <td>0.082775</td>\n",
       "      <td>0.251321</td>\n",
       "      <td>-0.144674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.755923</td>\n",
       "      <td>0.168392</td>\n",
       "      <td>0.446963</td>\n",
       "      <td>0.014414</td>\n",
       "      <td>-0.184862</td>\n",
       "      <td>0.114084</td>\n",
       "      <td>0.198372</td>\n",
       "      <td>0.713202</td>\n",
       "      <td>0.119248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_above</th>\n",
       "      <td>-0.010842</td>\n",
       "      <td>0.605567</td>\n",
       "      <td>0.477600</td>\n",
       "      <td>0.685342</td>\n",
       "      <td>0.876597</td>\n",
       "      <td>0.183512</td>\n",
       "      <td>0.523885</td>\n",
       "      <td>0.072075</td>\n",
       "      <td>0.167649</td>\n",
       "      <td>-0.158214</td>\n",
       "      <td>0.755923</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.051943</td>\n",
       "      <td>0.423898</td>\n",
       "      <td>0.023285</td>\n",
       "      <td>-0.261190</td>\n",
       "      <td>-0.000816</td>\n",
       "      <td>0.343803</td>\n",
       "      <td>0.731870</td>\n",
       "      <td>0.194050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_basement</th>\n",
       "      <td>-0.005151</td>\n",
       "      <td>0.323816</td>\n",
       "      <td>0.303093</td>\n",
       "      <td>0.283770</td>\n",
       "      <td>0.435043</td>\n",
       "      <td>0.015286</td>\n",
       "      <td>-0.245705</td>\n",
       "      <td>0.080588</td>\n",
       "      <td>0.276947</td>\n",
       "      <td>0.174105</td>\n",
       "      <td>0.168392</td>\n",
       "      <td>-0.051943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.133124</td>\n",
       "      <td>0.071323</td>\n",
       "      <td>0.074845</td>\n",
       "      <td>0.110538</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>0.200355</td>\n",
       "      <td>0.017276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yr_built</th>\n",
       "      <td>0.021380</td>\n",
       "      <td>0.054012</td>\n",
       "      <td>0.154178</td>\n",
       "      <td>0.506019</td>\n",
       "      <td>0.318049</td>\n",
       "      <td>0.053080</td>\n",
       "      <td>0.489319</td>\n",
       "      <td>-0.026161</td>\n",
       "      <td>-0.053440</td>\n",
       "      <td>-0.361417</td>\n",
       "      <td>0.446963</td>\n",
       "      <td>0.423898</td>\n",
       "      <td>-0.133124</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.224874</td>\n",
       "      <td>-0.346869</td>\n",
       "      <td>-0.148122</td>\n",
       "      <td>0.409356</td>\n",
       "      <td>0.326229</td>\n",
       "      <td>0.070958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yr_renovated</th>\n",
       "      <td>-0.016907</td>\n",
       "      <td>0.126434</td>\n",
       "      <td>0.018841</td>\n",
       "      <td>0.050739</td>\n",
       "      <td>0.055363</td>\n",
       "      <td>0.007644</td>\n",
       "      <td>0.006338</td>\n",
       "      <td>0.092885</td>\n",
       "      <td>0.103917</td>\n",
       "      <td>-0.060618</td>\n",
       "      <td>0.014414</td>\n",
       "      <td>0.023285</td>\n",
       "      <td>0.071323</td>\n",
       "      <td>-0.224874</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064357</td>\n",
       "      <td>0.029398</td>\n",
       "      <td>-0.068372</td>\n",
       "      <td>-0.002673</td>\n",
       "      <td>0.007854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode</th>\n",
       "      <td>-0.008224</td>\n",
       "      <td>-0.053203</td>\n",
       "      <td>-0.152668</td>\n",
       "      <td>-0.203866</td>\n",
       "      <td>-0.199430</td>\n",
       "      <td>-0.129574</td>\n",
       "      <td>-0.059121</td>\n",
       "      <td>0.030285</td>\n",
       "      <td>0.084827</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>-0.184862</td>\n",
       "      <td>-0.261190</td>\n",
       "      <td>0.074845</td>\n",
       "      <td>-0.346869</td>\n",
       "      <td>0.064357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.267048</td>\n",
       "      <td>-0.564072</td>\n",
       "      <td>-0.279033</td>\n",
       "      <td>-0.147221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <td>-0.001891</td>\n",
       "      <td>0.307003</td>\n",
       "      <td>-0.008931</td>\n",
       "      <td>0.024573</td>\n",
       "      <td>0.052529</td>\n",
       "      <td>-0.085683</td>\n",
       "      <td>0.049614</td>\n",
       "      <td>-0.014274</td>\n",
       "      <td>0.006157</td>\n",
       "      <td>-0.014941</td>\n",
       "      <td>0.114084</td>\n",
       "      <td>-0.000816</td>\n",
       "      <td>0.110538</td>\n",
       "      <td>-0.148122</td>\n",
       "      <td>0.029398</td>\n",
       "      <td>0.267048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.135512</td>\n",
       "      <td>0.048858</td>\n",
       "      <td>-0.086419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long</th>\n",
       "      <td>0.020799</td>\n",
       "      <td>0.021626</td>\n",
       "      <td>0.129473</td>\n",
       "      <td>0.223042</td>\n",
       "      <td>0.240223</td>\n",
       "      <td>0.229521</td>\n",
       "      <td>0.125419</td>\n",
       "      <td>-0.041910</td>\n",
       "      <td>-0.078400</td>\n",
       "      <td>-0.106500</td>\n",
       "      <td>0.198372</td>\n",
       "      <td>0.343803</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>0.409356</td>\n",
       "      <td>-0.068372</td>\n",
       "      <td>-0.564072</td>\n",
       "      <td>-0.135512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334605</td>\n",
       "      <td>0.254451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_living15</th>\n",
       "      <td>-0.002901</td>\n",
       "      <td>0.585379</td>\n",
       "      <td>0.391638</td>\n",
       "      <td>0.568634</td>\n",
       "      <td>0.756420</td>\n",
       "      <td>0.144608</td>\n",
       "      <td>0.279885</td>\n",
       "      <td>0.086463</td>\n",
       "      <td>0.280439</td>\n",
       "      <td>-0.092824</td>\n",
       "      <td>0.713202</td>\n",
       "      <td>0.731870</td>\n",
       "      <td>0.200355</td>\n",
       "      <td>0.326229</td>\n",
       "      <td>-0.002673</td>\n",
       "      <td>-0.279033</td>\n",
       "      <td>0.048858</td>\n",
       "      <td>0.334605</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.183192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_lot15</th>\n",
       "      <td>-0.138798</td>\n",
       "      <td>0.082447</td>\n",
       "      <td>0.029244</td>\n",
       "      <td>0.087175</td>\n",
       "      <td>0.183286</td>\n",
       "      <td>0.718557</td>\n",
       "      <td>-0.011269</td>\n",
       "      <td>0.030703</td>\n",
       "      <td>0.072575</td>\n",
       "      <td>-0.003406</td>\n",
       "      <td>0.119248</td>\n",
       "      <td>0.194050</td>\n",
       "      <td>0.017276</td>\n",
       "      <td>0.070958</td>\n",
       "      <td>0.007854</td>\n",
       "      <td>-0.147221</td>\n",
       "      <td>-0.086419</td>\n",
       "      <td>0.254451</td>\n",
       "      <td>0.183192</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id     price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "id             1.000000 -0.016762  0.001286   0.005160    -0.012258 -0.132109   \n",
       "price         -0.016762  1.000000  0.308350   0.525138     0.702035  0.089661   \n",
       "bedrooms       0.001286  0.308350  1.000000   0.515884     0.576671  0.031703   \n",
       "bathrooms      0.005160  0.525138  0.515884   1.000000     0.754665  0.087740   \n",
       "sqft_living   -0.012258  0.702035  0.576671   0.754665     1.000000  0.172826   \n",
       "sqft_lot      -0.132109  0.089661  0.031703   0.087740     0.172826  1.000000   \n",
       "floors         0.018525  0.256794  0.175429   0.500653     0.353949 -0.005201   \n",
       "waterfront    -0.002721  0.266369 -0.006582   0.063744     0.103818  0.021604   \n",
       "view           0.011592  0.397293  0.079532   0.187737     0.284611  0.074710   \n",
       "condition     -0.023783  0.036362  0.028472  -0.124982    -0.058753 -0.008958   \n",
       "grade          0.008130  0.667434  0.356967   0.664983     0.762704  0.113621   \n",
       "sqft_above    -0.010842  0.605567  0.477600   0.685342     0.876597  0.183512   \n",
       "sqft_basement -0.005151  0.323816  0.303093   0.283770     0.435043  0.015286   \n",
       "yr_built       0.021380  0.054012  0.154178   0.506019     0.318049  0.053080   \n",
       "yr_renovated  -0.016907  0.126434  0.018841   0.050739     0.055363  0.007644   \n",
       "zipcode       -0.008224 -0.053203 -0.152668  -0.203866    -0.199430 -0.129574   \n",
       "lat           -0.001891  0.307003 -0.008931   0.024573     0.052529 -0.085683   \n",
       "long           0.020799  0.021626  0.129473   0.223042     0.240223  0.229521   \n",
       "sqft_living15 -0.002901  0.585379  0.391638   0.568634     0.756420  0.144608   \n",
       "sqft_lot15    -0.138798  0.082447  0.029244   0.087175     0.183286  0.718557   \n",
       "\n",
       "                 floors  waterfront      view  condition     grade  \\\n",
       "id             0.018525   -0.002721  0.011592  -0.023783  0.008130   \n",
       "price          0.256794    0.266369  0.397293   0.036362  0.667434   \n",
       "bedrooms       0.175429   -0.006582  0.079532   0.028472  0.356967   \n",
       "bathrooms      0.500653    0.063744  0.187737  -0.124982  0.664983   \n",
       "sqft_living    0.353949    0.103818  0.284611  -0.058753  0.762704   \n",
       "sqft_lot      -0.005201    0.021604  0.074710  -0.008958  0.113621   \n",
       "floors         1.000000    0.023698  0.029444  -0.263768  0.458183   \n",
       "waterfront     0.023698    1.000000  0.401857   0.016653  0.082775   \n",
       "view           0.029444    0.401857  1.000000   0.045990  0.251321   \n",
       "condition     -0.263768    0.016653  0.045990   1.000000 -0.144674   \n",
       "grade          0.458183    0.082775  0.251321  -0.144674  1.000000   \n",
       "sqft_above     0.523885    0.072075  0.167649  -0.158214  0.755923   \n",
       "sqft_basement -0.245705    0.080588  0.276947   0.174105  0.168392   \n",
       "yr_built       0.489319   -0.026161 -0.053440  -0.361417  0.446963   \n",
       "yr_renovated   0.006338    0.092885  0.103917  -0.060618  0.014414   \n",
       "zipcode       -0.059121    0.030285  0.084827   0.003026 -0.184862   \n",
       "lat            0.049614   -0.014274  0.006157  -0.014941  0.114084   \n",
       "long           0.125419   -0.041910 -0.078400  -0.106500  0.198372   \n",
       "sqft_living15  0.279885    0.086463  0.280439  -0.092824  0.713202   \n",
       "sqft_lot15    -0.011269    0.030703  0.072575  -0.003406  0.119248   \n",
       "\n",
       "               sqft_above  sqft_basement  yr_built  yr_renovated   zipcode  \\\n",
       "id              -0.010842      -0.005151  0.021380     -0.016907 -0.008224   \n",
       "price            0.605567       0.323816  0.054012      0.126434 -0.053203   \n",
       "bedrooms         0.477600       0.303093  0.154178      0.018841 -0.152668   \n",
       "bathrooms        0.685342       0.283770  0.506019      0.050739 -0.203866   \n",
       "sqft_living      0.876597       0.435043  0.318049      0.055363 -0.199430   \n",
       "sqft_lot         0.183512       0.015286  0.053080      0.007644 -0.129574   \n",
       "floors           0.523885      -0.245705  0.489319      0.006338 -0.059121   \n",
       "waterfront       0.072075       0.080588 -0.026161      0.092885  0.030285   \n",
       "view             0.167649       0.276947 -0.053440      0.103917  0.084827   \n",
       "condition       -0.158214       0.174105 -0.361417     -0.060618  0.003026   \n",
       "grade            0.755923       0.168392  0.446963      0.014414 -0.184862   \n",
       "sqft_above       1.000000      -0.051943  0.423898      0.023285 -0.261190   \n",
       "sqft_basement   -0.051943       1.000000 -0.133124      0.071323  0.074845   \n",
       "yr_built         0.423898      -0.133124  1.000000     -0.224874 -0.346869   \n",
       "yr_renovated     0.023285       0.071323 -0.224874      1.000000  0.064357   \n",
       "zipcode         -0.261190       0.074845 -0.346869      0.064357  1.000000   \n",
       "lat             -0.000816       0.110538 -0.148122      0.029398  0.267048   \n",
       "long             0.343803      -0.144765  0.409356     -0.068372 -0.564072   \n",
       "sqft_living15    0.731870       0.200355  0.326229     -0.002673 -0.279033   \n",
       "sqft_lot15       0.194050       0.017276  0.070958      0.007854 -0.147221   \n",
       "\n",
       "                    lat      long  sqft_living15  sqft_lot15  \n",
       "id            -0.001891  0.020799      -0.002901   -0.138798  \n",
       "price          0.307003  0.021626       0.585379    0.082447  \n",
       "bedrooms      -0.008931  0.129473       0.391638    0.029244  \n",
       "bathrooms      0.024573  0.223042       0.568634    0.087175  \n",
       "sqft_living    0.052529  0.240223       0.756420    0.183286  \n",
       "sqft_lot      -0.085683  0.229521       0.144608    0.718557  \n",
       "floors         0.049614  0.125419       0.279885   -0.011269  \n",
       "waterfront    -0.014274 -0.041910       0.086463    0.030703  \n",
       "view           0.006157 -0.078400       0.280439    0.072575  \n",
       "condition     -0.014941 -0.106500      -0.092824   -0.003406  \n",
       "grade          0.114084  0.198372       0.713202    0.119248  \n",
       "sqft_above    -0.000816  0.343803       0.731870    0.194050  \n",
       "sqft_basement  0.110538 -0.144765       0.200355    0.017276  \n",
       "yr_built      -0.148122  0.409356       0.326229    0.070958  \n",
       "yr_renovated   0.029398 -0.068372      -0.002673    0.007854  \n",
       "zipcode        0.267048 -0.564072      -0.279033   -0.147221  \n",
       "lat            1.000000 -0.135512       0.048858   -0.086419  \n",
       "long          -0.135512  1.000000       0.334605    0.254451  \n",
       "sqft_living15  0.048858  0.334605       1.000000    0.183192  \n",
       "sqft_lot15    -0.086419  0.254451       0.183192    1.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.580302e+09</td>\n",
       "      <td>5.400881e+05</td>\n",
       "      <td>3.370842</td>\n",
       "      <td>2.114757</td>\n",
       "      <td>2079.899736</td>\n",
       "      <td>1.510697e+04</td>\n",
       "      <td>1.494309</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.234303</td>\n",
       "      <td>3.409430</td>\n",
       "      <td>7.656873</td>\n",
       "      <td>1788.390691</td>\n",
       "      <td>291.509045</td>\n",
       "      <td>1971.005136</td>\n",
       "      <td>84.402258</td>\n",
       "      <td>98077.939805</td>\n",
       "      <td>47.560053</td>\n",
       "      <td>-122.213896</td>\n",
       "      <td>1986.552492</td>\n",
       "      <td>12768.455652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.876566e+09</td>\n",
       "      <td>3.671272e+05</td>\n",
       "      <td>0.930062</td>\n",
       "      <td>0.770163</td>\n",
       "      <td>918.440897</td>\n",
       "      <td>4.142051e+04</td>\n",
       "      <td>0.539989</td>\n",
       "      <td>0.086517</td>\n",
       "      <td>0.766318</td>\n",
       "      <td>0.650743</td>\n",
       "      <td>1.175459</td>\n",
       "      <td>828.090978</td>\n",
       "      <td>442.575043</td>\n",
       "      <td>29.373411</td>\n",
       "      <td>401.679240</td>\n",
       "      <td>53.505026</td>\n",
       "      <td>0.138564</td>\n",
       "      <td>0.140828</td>\n",
       "      <td>685.391304</td>\n",
       "      <td>27304.179631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000102e+06</td>\n",
       "      <td>7.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98001.000000</td>\n",
       "      <td>47.155900</td>\n",
       "      <td>-122.519000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>651.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.123049e+09</td>\n",
       "      <td>3.219500e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1427.000000</td>\n",
       "      <td>5.040000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1951.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98033.000000</td>\n",
       "      <td>47.471000</td>\n",
       "      <td>-122.328000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.904930e+09</td>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1910.000000</td>\n",
       "      <td>7.618000e+03</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1560.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1975.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98065.000000</td>\n",
       "      <td>47.571800</td>\n",
       "      <td>-122.230000</td>\n",
       "      <td>1840.000000</td>\n",
       "      <td>7620.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.308900e+09</td>\n",
       "      <td>6.450000e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>1.068800e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2210.000000</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98118.000000</td>\n",
       "      <td>47.678000</td>\n",
       "      <td>-122.125000</td>\n",
       "      <td>2360.000000</td>\n",
       "      <td>10083.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.900000e+09</td>\n",
       "      <td>7.700000e+06</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13540.000000</td>\n",
       "      <td>1.651359e+06</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9410.000000</td>\n",
       "      <td>4820.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>98199.000000</td>\n",
       "      <td>47.777600</td>\n",
       "      <td>-121.315000</td>\n",
       "      <td>6210.000000</td>\n",
       "      <td>871200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         price      bedrooms     bathrooms   sqft_living  \\\n",
       "count  2.161300e+04  2.161300e+04  21613.000000  21613.000000  21613.000000   \n",
       "mean   4.580302e+09  5.400881e+05      3.370842      2.114757   2079.899736   \n",
       "std    2.876566e+09  3.671272e+05      0.930062      0.770163    918.440897   \n",
       "min    1.000102e+06  7.500000e+04      0.000000      0.000000    290.000000   \n",
       "25%    2.123049e+09  3.219500e+05      3.000000      1.750000   1427.000000   \n",
       "50%    3.904930e+09  4.500000e+05      3.000000      2.250000   1910.000000   \n",
       "75%    7.308900e+09  6.450000e+05      4.000000      2.500000   2550.000000   \n",
       "max    9.900000e+09  7.700000e+06     33.000000      8.000000  13540.000000   \n",
       "\n",
       "           sqft_lot        floors    waterfront          view     condition  \\\n",
       "count  2.161300e+04  21613.000000  21613.000000  21613.000000  21613.000000   \n",
       "mean   1.510697e+04      1.494309      0.007542      0.234303      3.409430   \n",
       "std    4.142051e+04      0.539989      0.086517      0.766318      0.650743   \n",
       "min    5.200000e+02      1.000000      0.000000      0.000000      1.000000   \n",
       "25%    5.040000e+03      1.000000      0.000000      0.000000      3.000000   \n",
       "50%    7.618000e+03      1.500000      0.000000      0.000000      3.000000   \n",
       "75%    1.068800e+04      2.000000      0.000000      0.000000      4.000000   \n",
       "max    1.651359e+06      3.500000      1.000000      4.000000      5.000000   \n",
       "\n",
       "              grade    sqft_above  sqft_basement      yr_built  yr_renovated  \\\n",
       "count  21613.000000  21613.000000   21613.000000  21613.000000  21613.000000   \n",
       "mean       7.656873   1788.390691     291.509045   1971.005136     84.402258   \n",
       "std        1.175459    828.090978     442.575043     29.373411    401.679240   \n",
       "min        1.000000    290.000000       0.000000   1900.000000      0.000000   \n",
       "25%        7.000000   1190.000000       0.000000   1951.000000      0.000000   \n",
       "50%        7.000000   1560.000000       0.000000   1975.000000      0.000000   \n",
       "75%        8.000000   2210.000000     560.000000   1997.000000      0.000000   \n",
       "max       13.000000   9410.000000    4820.000000   2015.000000   2015.000000   \n",
       "\n",
       "            zipcode           lat          long  sqft_living15     sqft_lot15  \n",
       "count  21613.000000  21613.000000  21613.000000   21613.000000   21613.000000  \n",
       "mean   98077.939805     47.560053   -122.213896    1986.552492   12768.455652  \n",
       "std       53.505026      0.138564      0.140828     685.391304   27304.179631  \n",
       "min    98001.000000     47.155900   -122.519000     399.000000     651.000000  \n",
       "25%    98033.000000     47.471000   -122.328000    1490.000000    5100.000000  \n",
       "50%    98065.000000     47.571800   -122.230000    1840.000000    7620.000000  \n",
       "75%    98118.000000     47.678000   -122.125000    2360.000000   10083.000000  \n",
       "max    98199.000000     47.777600   -121.315000    6210.000000  871200.000000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test set 80/20\n",
    "\n",
    "The test set is partitioned off to determine a final performance metric for the \n",
    "best model found during training on new unseen, unlabeled data.\n",
    "\n",
    "The remaining 80% of the data is used for training. 5-fold cross validation is \n",
    "performed on each model. The performance is measured using mean squared error \n",
    "and r2 on the validation set and the average performance across all 5 folds is \n",
    "calculated. Hyperparameters are tuned to improve the performance of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split data into train and test set 80/20\n",
    "X_Train, X_test, y_Train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "ID and date are dropped from the attributes since they are highly uncorrelated \n",
    "from the price. Further attributes could be excluded due to lack of correlation \n",
    "(sqft_lot, condition, yr_built, zipcode, longitude) or due to high correlation \n",
    "with other variables (sqft_living15, sqft_lot15), but for the initial analysis \n",
    "most attributes were preserved to ensure no useful features were dropped. If \n",
    "more models and hyperparameters were trained on, the attributes would have to \n",
    "be pruned to speed up computation times.\n",
    "\n",
    "5-fold cross validation is used to determine the performance of a model without \n",
    "sacrificing an additional proportion of the data to a validation set. k-fold \n",
    "cross validation is performed by splitting the training data in k equal \n",
    "partitions, then training the data on all but one of the partitions and \n",
    "determining the performance of the fold on the validation set. Each fold is \n",
    "trained in this way. The final performance is calculated from the mean of the \n",
    "performance on each fold.\n",
    "\n",
    "GridSearchCV automatically performs hyperparameters selection and k-fold cross \n",
    "validation on a specified hyperparameter space. GridSearchCV outputs the best \n",
    "performing model in the hyperparameter space.\n",
    "\n",
    "Mean squared error measures the sum of the (target - predicted) ^ 2. A lower \n",
    "mse is better, zero mse means the data was predicted perfectly.\n",
    "\n",
    "r2 measures the variation between the target and predicted values. A value \n",
    "close to 1 indicates the predictions were close to the corresponding target. A \n",
    "value close to 0 indicates the model always predicts a value close to the \n",
    "sample mean. A negative value indicates the performance is worse than flipping \n",
    "a coin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 42291601576.0\n",
      "r2 score: 0.687056548023\n",
      "Mean squared error: 44126734512.9\n",
      "r2 score: 0.684543852893\n",
      "Mean squared error: 44728535039.1\n",
      "r2 score: 0.691005376231\n",
      "Mean squared error: 36630033755.9\n",
      "r2 score: 0.714354890126\n",
      "Mean squared error: 34375558508.5\n",
      "r2 score: 0.71668476553\n",
      "\n",
      "mean mse: 40430492678.5\n",
      "mean r2: 0.698729086561\n"
     ]
    }
   ],
   "source": [
    "# Linear regression\n",
    "lr = LinearRegression()\n",
    "mses = []\n",
    "r2s = []\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "for train_index, validation_index in kf.split(X_Train):\n",
    "    X_train, X_validation = X[train_index], X[validation_index]\n",
    "    y_train, y_validation = y[train_index], y[validation_index]\n",
    "    \n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_validation)\n",
    "    mse = mean_squared_error(y_validation, y_pred)\n",
    "    r2 = r2_score(y_validation, y_pred)\n",
    "    #print(\"Coefficients:\\n\", lr.coef_)\n",
    "    mses.append(mse)\n",
    "    r2s.append(r2)\n",
    "    print(\"Mean squared error:\", mse)\n",
    "    print(\"r2 score:\", r2)\n",
    "print(\"\\nmean mse:\", np.mean(mses))\n",
    "print(\"mean r2:\", np.mean(r2s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso regression, mean_squared_error\n",
    "\n",
    "From eq. 3.29 in the book, lasso regression performs regularization with q=1 to \n",
    "reduce the magnitude of the coefficients in an attempt to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Estimator: Lasso(alpha=2, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=0,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "Best score: mean_squared_error = -42254982541.4\n",
      "Best parameters: {'alpha': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Lasso regression, mean_squared_error\n",
    "# regularization coeff: [0.001, 0.01, 0.1, 1, 2]\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "parameters = {'alpha' : [0.001, 0.01, 0.1, 1, 2]}\n",
    "lasso = Lasso(random_state=0, max_iter=1000)\n",
    "\n",
    "clf = GridSearchCV(lasso, parameters, cv=5, scoring='neg_mean_squared_error')\n",
    "clf.fit(X_Train, y_Train)\n",
    "#pp.pprint(clf.cv_results_)\n",
    "print(\"\\nBest Estimator:\", clf.best_estimator_)\n",
    "print(\"Best score: mean_squared_error =\", clf.best_score_)\n",
    "print(\"Best parameters:\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso regression, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ...................................... alpha=0.001, total=   0.1s\n",
      "[CV] alpha=0.001 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................................... alpha=0.001, total=   0.1s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ...................................... alpha=0.001, total=   0.1s\n",
      "[CV] alpha=0.001 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................................... alpha=0.001, total=   0.1s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ...................................... alpha=0.001, total=   0.1s\n",
      "[CV] alpha=0.01 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................................... alpha=0.01, total=   0.1s\n",
      "[CV] alpha=0.01 ......................................................\n",
      "[CV] ....................................... alpha=0.01, total=   0.1s\n",
      "[CV] alpha=0.01 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................................... alpha=0.01, total=   0.1s\n",
      "[CV] alpha=0.01 ......................................................\n",
      "[CV] ....................................... alpha=0.01, total=   0.1s\n",
      "[CV] alpha=0.01 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................................... alpha=0.01, total=   0.1s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ........................................ alpha=0.1, total=   0.1s\n",
      "[CV] alpha=0.1 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................................ alpha=0.1, total=   0.2s\n",
      "[CV] alpha=0.1 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................................ alpha=0.1, total=   0.3s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ........................................ alpha=0.1, total=   0.0s\n",
      "[CV] alpha=0.1 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................................ alpha=0.1, total=   0.1s\n",
      "[CV] alpha=1 .........................................................\n",
      "[CV] .......................................... alpha=1, total=   0.1s\n",
      "[CV] alpha=1 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................................... alpha=1, total=   0.1s\n",
      "[CV] alpha=1 .........................................................\n",
      "[CV] .......................................... alpha=1, total=   0.1s\n",
      "[CV] alpha=1 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................................... alpha=1, total=   0.1s\n",
      "[CV] alpha=1 .........................................................\n",
      "[CV] .......................................... alpha=1, total=   0.1s\n",
      "[CV] alpha=2 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................................... alpha=2, total=   0.1s\n",
      "[CV] alpha=2 .........................................................\n",
      "[CV] .......................................... alpha=2, total=   0.1s\n",
      "[CV] alpha=2 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................................... alpha=2, total=   0.1s\n",
      "[CV] alpha=2 .........................................................\n",
      "[CV] .......................................... alpha=2, total=   0.1s\n",
      "[CV] alpha=2 .........................................................\n",
      "[CV] .......................................... alpha=2, total=   0.2s\n",
      "\n",
      "Best Estimator: Lasso(alpha=2, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=0,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "Best score: r2_score = 0.695673188325\n",
      "Best parameters: {'alpha': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    4.6s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Lasso regression, r2_score\n",
    "# regularization coeff: [0.001, 0.01, 0.1, 1, 2]\n",
    "parameters = {'alpha' : [0.001, 0.01, 0.1, 1, 2]}\n",
    "lasso = Lasso(random_state=0, max_iter=1000)\n",
    "\n",
    "clf = GridSearchCV(lasso, parameters, cv=5, scoring='r2', verbose=2)\n",
    "clf.fit(X_Train, y_Train)\n",
    "#pp.pprint(clf.cv_results_)\n",
    "print(\"\\nBest Estimator:\", clf.best_estimator_)\n",
    "print(\"Best score: r2_score =\", clf.best_score_)\n",
    "print(\"Best parameters:\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel ridge regression, mean_squared_error\n",
    "\n",
    "Eq. 3.29 with q=2. More heavily penalized larger coefficients that lasso. \n",
    "Kernel methods are used to implicitly transform the input space from linear \n",
    "to polynomial of various degrees and to a gaussian space (rbf) with various \n",
    "gamma coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] kernel=linear ...................................................\n",
      "[CV] .................................... kernel=linear, total=  10.8s\n",
      "[CV] kernel=linear ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... kernel=linear, total=  10.2s\n",
      "[CV] kernel=linear ...................................................\n",
      "[CV] .................................... kernel=linear, total=  10.7s\n",
      "[CV] kernel=linear ...................................................\n",
      "[CV] .................................... kernel=linear, total=   9.9s\n",
      "[CV] kernel=linear ...................................................\n",
      "[CV] .................................... kernel=linear, total=  10.0s\n",
      "[CV] degree=2, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=2, kernel=poly, total= 8.9min\n",
      "[CV] degree=2, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=2, kernel=poly, total= 8.8min\n",
      "[CV] degree=2, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=2, kernel=poly, total= 8.8min\n",
      "[CV] degree=2, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................... degree=2, kernel=poly, total=274.0min\n",
      "[CV] degree=2, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=2, kernel=poly, total= 8.8min\n",
      "[CV] degree=4, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=4, kernel=poly, total= 8.8min\n",
      "[CV] degree=4, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=4, kernel=poly, total= 8.9min\n",
      "[CV] degree=4, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=4, kernel=poly, total= 9.1min\n",
      "[CV] degree=4, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=4, kernel=poly, total= 8.9min\n",
      "[CV] degree=4, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=4, kernel=poly, total= 9.4min\n",
      "[CV] degree=7, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=7, kernel=poly, total= 9.5min\n",
      "[CV] degree=7, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=7, kernel=poly, total= 8.8min\n",
      "[CV] degree=7, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=7, kernel=poly, total= 8.8min\n",
      "[CV] degree=7, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=7, kernel=poly, total= 8.8min\n",
      "[CV] degree=7, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=7, kernel=poly, total= 8.8min\n",
      "[CV] gamma=0.1, kernel=rbf ...........................................\n",
      "[CV] ............................ gamma=0.1, kernel=rbf, total=  19.1s\n",
      "[CV] gamma=0.1, kernel=rbf ...........................................\n",
      "[CV] ............................ gamma=0.1, kernel=rbf, total=  19.0s\n",
      "[CV] gamma=0.1, kernel=rbf ...........................................\n",
      "[CV] ............................ gamma=0.1, kernel=rbf, total=  19.1s\n",
      "[CV] gamma=0.1, kernel=rbf ...........................................\n",
      "[CV] ............................ gamma=0.1, kernel=rbf, total=  19.2s\n",
      "[CV] gamma=0.1, kernel=rbf ...........................................\n",
      "[CV] ............................ gamma=0.1, kernel=rbf, total=  19.5s\n",
      "[CV] gamma=0.5, kernel=rbf ...........................................\n",
      "[CV] ............................ gamma=0.5, kernel=rbf, total=  19.4s\n",
      "[CV] gamma=0.5, kernel=rbf ...........................................\n",
      "[CV] ............................ gamma=0.5, kernel=rbf, total=  19.2s\n",
      "[CV] gamma=0.5, kernel=rbf ...........................................\n",
      "[CV] ............................ gamma=0.5, kernel=rbf, total=  19.1s\n",
      "[CV] gamma=0.5, kernel=rbf ...........................................\n",
      "[CV] ............................ gamma=0.5, kernel=rbf, total=  19.2s\n",
      "[CV] gamma=0.5, kernel=rbf ...........................................\n",
      "[CV] ............................ gamma=0.5, kernel=rbf, total=  19.2s\n",
      "[CV] gamma=1, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=1, kernel=rbf, total=  19.5s\n",
      "[CV] gamma=1, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=1, kernel=rbf, total=  19.2s\n",
      "[CV] gamma=1, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=1, kernel=rbf, total=  19.1s\n",
      "[CV] gamma=1, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=1, kernel=rbf, total=  19.1s\n",
      "[CV] gamma=1, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=1, kernel=rbf, total=  19.1s\n",
      "[CV] gamma=2, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=2, kernel=rbf, total=  19.2s\n",
      "[CV] gamma=2, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=2, kernel=rbf, total=  19.1s\n",
      "[CV] gamma=2, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=2, kernel=rbf, total=  19.2s\n",
      "[CV] gamma=2, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=2, kernel=rbf, total=  19.7s\n",
      "[CV] gamma=2, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=2, kernel=rbf, total=  19.2s\n",
      "[CV] gamma=4, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=4, kernel=rbf, total=  19.1s\n",
      "[CV] gamma=4, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=4, kernel=rbf, total=  19.1s\n",
      "[CV] gamma=4, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=4, kernel=rbf, total=  19.2s\n",
      "[CV] gamma=4, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=4, kernel=rbf, total=  19.1s\n",
      "[CV] gamma=4, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=4, kernel=rbf, total=  19.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 413.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Estimator: KernelRidge(alpha=1, coef0=1, degree=3, gamma=None, kernel='linear',\n",
      "      kernel_params=None)\n",
      "Best score: mean_squared_error = -42234850075.7\n",
      "Best parameters: {'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Kernel ridge regression, mean_squared_error\n",
    "krrParameters = [{'kernel':['linear']},\n",
    "                 {'kernel':['poly'], 'degree':[2,4,7]},\n",
    "                 {'kernel':['rbf'], 'gamma':[0.1,0.5,1,2,4]},\n",
    "                 # coef0 = 1 # defaults to 1 for poly and sigmoid, else ignored\n",
    "                ]\n",
    "\n",
    "krr = KernelRidge()\n",
    "\n",
    "clf2 = GridSearchCV(krr, krrParameters, cv=5, scoring='neg_mean_squared_error',\n",
    "                   verbose=2)\n",
    "clf2.fit(X_Train, y_Train)\n",
    "#pp.pprint(clf2.cv_results_)\n",
    "print(\"\\nBest Estimator:\", clf2.best_estimator_)\n",
    "print(\"Best score: mean_squared_error =\", clf2.best_score_)\n",
    "print(\"Best parameters:\", clf2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel ridge regression, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] kernel=linear ...................................................\n",
      "[CV] .................................... kernel=linear, total=  10.2s\n",
      "[CV] kernel=linear ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... kernel=linear, total=  10.0s\n",
      "[CV] kernel=linear ...................................................\n",
      "[CV] .................................... kernel=linear, total=   9.9s\n",
      "[CV] kernel=linear ...................................................\n",
      "[CV] .................................... kernel=linear, total=  10.3s\n",
      "[CV] kernel=linear ...................................................\n",
      "[CV] .................................... kernel=linear, total=  10.1s\n",
      "[CV] degree=2, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=2, kernel=poly, total= 8.9min\n",
      "[CV] degree=2, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=2, kernel=poly, total= 8.7min\n",
      "[CV] degree=2, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=2, kernel=poly, total= 8.7min\n",
      "[CV] degree=2, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=2, kernel=poly, total= 8.8min\n",
      "[CV] degree=2, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=2, kernel=poly, total= 8.7min\n",
      "[CV] degree=4, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=4, kernel=poly, total= 8.8min\n",
      "[CV] degree=4, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=4, kernel=poly, total= 8.8min\n",
      "[CV] degree=4, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=4, kernel=poly, total= 8.8min\n",
      "[CV] degree=4, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=4, kernel=poly, total= 8.8min\n",
      "[CV] degree=4, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=4, kernel=poly, total= 8.8min\n",
      "[CV] degree=7, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=7, kernel=poly, total= 8.8min\n",
      "[CV] degree=7, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=7, kernel=poly, total= 9.0min\n",
      "[CV] degree=7, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=7, kernel=poly, total= 8.9min\n",
      "[CV] degree=7, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=7, kernel=poly, total= 8.8min\n",
      "[CV] degree=7, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:154: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ degree=7, kernel=poly, total= 8.8min\n",
      "[CV] gamma=0.1, kernel=rbf ...........................................\n",
      "[CV] ............................ gamma=0.1, kernel=rbf, total=  19.1s\n",
      "[CV] gamma=0.1, kernel=rbf ...........................................\n",
      "[CV] ............................ gamma=0.1, kernel=rbf, total=  19.2s\n",
      "[CV] gamma=0.1, kernel=rbf ...........................................\n",
      "[CV] ............................ gamma=0.1, kernel=rbf, total=  19.0s\n",
      "[CV] gamma=0.1, kernel=rbf ...........................................\n",
      "[CV] ............................ gamma=0.1, kernel=rbf, total=  19.0s\n",
      "[CV] gamma=0.1, kernel=rbf ...........................................\n",
      "[CV] ............................ gamma=0.1, kernel=rbf, total=  19.0s\n",
      "[CV] gamma=0.5, kernel=rbf ...........................................\n",
      "[CV] ............................ gamma=0.5, kernel=rbf, total=  19.1s\n",
      "[CV] gamma=0.5, kernel=rbf ...........................................\n",
      "[CV] ............................ gamma=0.5, kernel=rbf, total=  19.0s\n",
      "[CV] gamma=0.5, kernel=rbf ...........................................\n",
      "[CV] ............................ gamma=0.5, kernel=rbf, total=  19.0s\n",
      "[CV] gamma=0.5, kernel=rbf ...........................................\n",
      "[CV] ............................ gamma=0.5, kernel=rbf, total=  19.0s\n",
      "[CV] gamma=0.5, kernel=rbf ...........................................\n",
      "[CV] ............................ gamma=0.5, kernel=rbf, total=  19.0s\n",
      "[CV] gamma=1, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=1, kernel=rbf, total=  19.1s\n",
      "[CV] gamma=1, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=1, kernel=rbf, total=  19.9s\n",
      "[CV] gamma=1, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=1, kernel=rbf, total=  19.1s\n",
      "[CV] gamma=1, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=1, kernel=rbf, total=  19.0s\n",
      "[CV] gamma=1, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=1, kernel=rbf, total=  19.0s\n",
      "[CV] gamma=2, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=2, kernel=rbf, total=  19.0s\n",
      "[CV] gamma=2, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=2, kernel=rbf, total=  19.0s\n",
      "[CV] gamma=2, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=2, kernel=rbf, total=  19.0s\n",
      "[CV] gamma=2, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=2, kernel=rbf, total=  19.1s\n",
      "[CV] gamma=2, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=2, kernel=rbf, total=  19.2s\n",
      "[CV] gamma=4, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=4, kernel=rbf, total=  19.1s\n",
      "[CV] gamma=4, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=4, kernel=rbf, total=  19.1s\n",
      "[CV] gamma=4, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=4, kernel=rbf, total=  19.1s\n",
      "[CV] gamma=4, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=4, kernel=rbf, total=  19.1s\n",
      "[CV] gamma=4, kernel=rbf .............................................\n",
      "[CV] .............................. gamma=4, kernel=rbf, total=  19.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 146.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Estimator: KernelRidge(alpha=1, coef0=1, degree=3, gamma=None, kernel='linear',\n",
      "      kernel_params=None)\n",
      "Best score: r2_score = 0.695825356018\n",
      "Best parameters: {'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Kernel ridge regression, r2_score\n",
    "krrParameters = [{'kernel':['linear']},\n",
    "                 {'kernel':['poly'], 'degree':[2,4,7]},\n",
    "                 {'kernel':['rbf'], 'gamma':[0.1,0.5,1,2,4]},\n",
    "                 # coef0 = 1 # defaults to 1 for poly and sigmoid, else ignored\n",
    "                ]\n",
    "\n",
    "krr = KernelRidge()\n",
    "\n",
    "clf3 = GridSearchCV(krr, krrParameters, cv=5, scoring='r2',\n",
    "                   verbose=2)\n",
    "clf3.fit(X_Train, y_Train)\n",
    "#pp.pprint(clf3.cv_results_)\n",
    "print(\"\\nBest Estimator:\", clf3.best_estimator_)\n",
    "print(\"Best score: r2_score =\", clf3.best_score_)\n",
    "print(\"Best parameters:\", clf3.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression, reducing the number of attributes\n",
    "\n",
    "Reducing the number of attributes very slightly improve performance. This shows that the parameters that were discarded did not contribute the price of the house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 40458284750.7\n",
      "r2 score: 0.712504799624\n",
      "Mean squared error: 41929138527.1\n",
      "r2 score: 0.683166661448\n",
      "Mean squared error: 39198535331.4\n",
      "r2 score: 0.703518851339\n",
      "Mean squared error: 39432512208.0\n",
      "r2 score: 0.698847106942\n",
      "Mean squared error: 40407963781.4\n",
      "r2 score: 0.696693486873\n",
      "\n",
      "mean mse: 40285286919.7\n",
      "mean r2: 0.698946181245\n"
     ]
    }
   ],
   "source": [
    "# Linear regression, reducing the number of attributes\n",
    "\n",
    "X_Train2 = X_Train[:,[0,1,2,4,5,6,8,9,10]]\n",
    "\n",
    "lr2 = LinearRegression()\n",
    "mses2 = []\n",
    "r2s2 = []\n",
    "\n",
    "kf2 = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "for train_index, validation_index in kf2.split(X_Train2):\n",
    "    X_train, X_validation = X[train_index], X[validation_index]\n",
    "    y_train, y_validation = y[train_index], y[validation_index]\n",
    "    \n",
    "    lr2.fit(X_train, y_train)\n",
    "    y_pred2 = lr2.predict(X_validation)\n",
    "    mse2 = mean_squared_error(y_validation, y_pred2)\n",
    "    r22 = r2_score(y_validation, y_pred2)\n",
    "    #print(\"Coefficients:\\n\", lr.coef_)\n",
    "    mses2.append(mse2)\n",
    "    r2s2.append(r22)\n",
    "    print(\"Mean squared error:\", mse2)\n",
    "    print(\"r2 score:\", r22)\n",
    "print(\"\\nmean mse:\", np.mean(mses2))\n",
    "print(\"mean r2:\", np.mean(r2s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results of Training\n",
    "Linear  \n",
    "mean mse: 40430492678.5  \n",
    "mean r2: 0.698729086561\n",
    "\n",
    "Lasso  \n",
    "Best parameters: {'alpha': 2}  \n",
    "Best score: mean_squared_error = -42254982541.4  \n",
    "Best score: r2_score = 0.695673188325\n",
    "\n",
    "Kernel Ridge  \n",
    "Best parameters: {'kernel': 'linear'}  \n",
    "Best score: mean_squared_error = -42234850075.7  \n",
    "Best score: r2_score = 0.695825356018\n",
    "\n",
    "Linear, reduced attributes  \n",
    "mean mse: 40285286919.7  \n",
    "mean r2: 0.698946181245\n",
    "\n",
    "The linear model with the reduced number of attributes performed the best. This model was chosen to run the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 36315330765.0\n",
      "r2 score: 0.694634821136\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr2.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "#print(\"Coefficients:\\n\", lr.coef_)\n",
    "\n",
    "print(\"Mean squared error:\", mse)\n",
    "print(\"r2 score:\", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
